{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 2: Tool Integration for Agents\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand what tools are and why agents need them\n",
    "- Create tools using the `@tool` decorator\n",
    "- Bind tools to LLMs for function calling\n",
    "- Implement conditional routing based on tool calls\n",
    "- Build an agent that decides which tools to use\n",
    "\n",
    "**Prerequisites:** Topic 1 (LangGraph Basics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Why Do Agents Need Tools?\n",
    "\n",
    "### The Problem: LLMs Can't Do Everything\n",
    "\n",
    "LLMs are great at:\n",
    "- ‚úÖ Understanding language\n",
    "- ‚úÖ Generating text\n",
    "- ‚úÖ Reasoning about information\n",
    "\n",
    "But they **can't**:\n",
    "- ‚ùå Search the web in real-time\n",
    "- ‚ùå Perform precise calculations\n",
    "- ‚ùå Access databases or files\n",
    "- ‚ùå Call APIs\n",
    "- ‚ùå Execute code\n",
    "\n",
    "### The Solution: Tools!\n",
    "\n",
    "**Tools** are functions that agents can call to perform actions:\n",
    "\n",
    "```\n",
    "User: \"What's 12345 * 67890?\"\n",
    "\n",
    "Agent thinks: \"I need to calculate this precisely\"\n",
    "         ‚Üì\n",
    "Agent calls: calculator_tool(\"12345 * 67890\")\n",
    "         ‚Üì\n",
    "Tool returns: \"838102050\"\n",
    "         ‚Üì\n",
    "Agent responds: \"The answer is 838,102,050\"\n",
    "```\n",
    "\n",
    "This is the foundation of **agentic behavior** - agents that can DO things!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ü§î Reflection Question:** \n",
    "How is this different from just calling functions in your code? The key is that the **agent decides** when to call the tool - you don't hardcode it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install -q langgraph langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key loaded\n"
     ]
    }
   ],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"gen_api_key\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\"‚úÖ API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,  # Lower temperature for more precise tool usage\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Creating Your First Tool\n",
    "\n",
    "Let's start with a simple calculator tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The @tool Decorator\n",
    "\n",
    "The `@tool` decorator converts a Python function into a tool that LLMs can call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Calculator tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluate a mathematical expression and return the result.\n",
    "    Use this tool when you need to perform calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression like \"2 + 2\" or \"15 * 37\"\n",
    "        \n",
    "    Returns:\n",
    "        The calculated result as a string\n",
    "        \n",
    "    Examples:\n",
    "        - \"2 + 2\" returns \"4\"\n",
    "        - \"100 / 5\" returns \"20.0\"\n",
    "        - \"2 ** 10\" returns \"1024\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Evaluate the expression safely\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Calculator tool created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Key Components of a Good Tool:**\n",
    "\n",
    "1. **Clear docstring** - LLM reads this to understand when to use the tool!\n",
    "2. **Type hints** - Helps LLM know what arguments to provide\n",
    "3. **Examples** - Shows LLM how to use the tool\n",
    "4. **Error handling** - Gracefully handle failures\n",
    "5. **Return string** - LLMs work best with string outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Tool Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 * 456 = 56088\n",
      "2^10 = 1024\n"
     ]
    }
   ],
   "source": [
    "# Test the calculator tool\n",
    "result = calculator.invoke({\"expression\": \"123 * 456\"})\n",
    "print(f\"123 * 456 = {result}\")\n",
    "\n",
    "result2 = calculator.invoke(\"2 ** 10\")\n",
    "print(f\"2^10 = {result2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Creating a Second Tool\n",
    "\n",
    "Agents are more useful with multiple tools! Let's add a string manipulation tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text analyzer tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def text_analyzer(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze text and return statistics about it.\n",
    "    Use this tool when you need to analyze or count things in text.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Statistics about the text (characters, words, sentences)\n",
    "        \n",
    "    Examples:\n",
    "        - \"Hello world\" returns character count, word count, etc.\n",
    "    \"\"\"\n",
    "    char_count = len(text)\n",
    "    word_count = len(text.split())\n",
    "    sentence_count = text.count('.') + text.count('!') + text.count('?')\n",
    "    \n",
    "    return f\"\"\"Text Analysis:\n",
    "- Characters: {char_count}\n",
    "- Words: {word_count}\n",
    "- Sentences: {sentence_count}\n",
    "- First 50 chars: {text[:50]}...\"\"\"\n",
    "\n",
    "print(\"‚úÖ Text analyzer tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Analysis:\n",
      "- Characters: 41\n",
      "- Words: 9\n",
      "- Sentences: 3\n",
      "- First 50 chars: Hello! This is a test. How are you today?...\n"
     ]
    }
   ],
   "source": [
    "# Test the text analyzer\n",
    "test_text = \"Hello! This is a test. How are you today?\"\n",
    "result = text_analyzer.invoke({\"text\": test_text})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Binding Tools to the LLM\n",
    "\n",
    "Now we need to tell the LLM about our tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM bound to 2 tools\n",
      "   Tools: ['calculator', 'text_analyzer']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of tools\n",
    "tools = [calculator, text_analyzer]\n",
    "\n",
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(f\"‚úÖ LLM bound to {len(tools)} tools\")\n",
    "print(f\"   Tools: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What `bind_tools` does:**\n",
    "1. Sends tool descriptions to the LLM\n",
    "2. LLM can now \"see\" what tools are available\n",
    "3. LLM will decide when to call tools based on user queries\n",
    "\n",
    "This uses **OpenAI's function calling** feature - the LLM returns structured tool calls!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: LLM Decision Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "\n",
      "Content: \n",
      "\n",
      "Tool calls: [{'name': 'calculator', 'args': {'expression': '234 * 567'}, 'id': 'call_3tOLX2L8WucTHNnKKtJ7Q9t6', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# Test: Does LLM decide to call calculator?\n",
    "response = llm_with_tools.invoke([HumanMessage(content=\"What is 234 * 567?\")])\n",
    "\n",
    "print(f\"Response type: {type(response)}\")\n",
    "print(f\"\\nContent: {response.content}\")\n",
    "print(f\"\\nTool calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Key Observation:** \n",
    "The LLM didn't return a direct answer - it returned a **tool call**! This is the agent saying \"I need to use the calculator tool.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "Tool calls: []\n"
     ]
    }
   ],
   "source": [
    "# Test: Does LLM decide NOT to call tools for simple queries?\n",
    "response2 = llm_with_tools.invoke([HumanMessage(content=\"Hello! How are you?\")])\n",
    "\n",
    "print(f\"Content: {response2.content}\")\n",
    "print(f\"Tool calls: {response2.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Smart Decision:** The LLM knows it doesn't need tools for greetings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Building the Agent Graph\n",
    "\n",
    "Now let's build a complete agent that can use these tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the Assistant Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Assistant node defined\n"
     ]
    }
   ],
   "source": [
    "# System prompt that encourages tool usage\n",
    "sys_msg = SystemMessage(content=\"\"\"You are a helpful assistant with access to tools.\n",
    "\n",
    "When asked to perform calculations, use the calculator tool.\n",
    "When asked to analyze text, use the text_analyzer tool.\n",
    "\n",
    "Only use tools when necessary - for simple questions, answer directly.\"\"\")\n",
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Assistant node - decides whether to use tools or answer directly.\n",
    "    \"\"\"\n",
    "    messages = [sys_msg] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"‚úÖ Assistant node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Conditional Routing\n",
    "\n",
    "This is the **key to agentic behavior** - the graph decides where to go based on whether tools were called!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conditional routing function defined\n"
     ]
    }
   ],
   "source": [
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Decide next step based on last message.\n",
    "    \n",
    "    If LLM called a tool ‚Üí go to 'tools' node\n",
    "    If LLM provided final answer ‚Üí go to END\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # Check if LLM made tool calls\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # No tool calls - we're done\n",
    "    return \"__end__\"\n",
    "\n",
    "print(\"‚úÖ Conditional routing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîç Understanding the Flow:**\n",
    "\n",
    "```\n",
    "User Query ‚Üí Assistant Node ‚Üí Tool calls?\n",
    "                                  ‚îú‚îÄ YES ‚Üí Tools Node ‚Üí Back to Assistant\n",
    "                                  ‚îî‚îÄ NO  ‚Üí END (return answer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent graph compiled with tools and memory\n"
     ]
    }
   ],
   "source": [
    "# Create the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))  # ToolNode executes tool calls automatically\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")  # After tools, go back to assistant\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"‚úÖ Agent graph compiled with tools and memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Note on ToolNode:**\n",
    "`ToolNode(tools)` is a LangGraph helper that:\n",
    "1. Reads tool calls from the last message\n",
    "2. Executes the appropriate tool\n",
    "3. Returns results as ToolMessage\n",
    "\n",
    "This saves us from manually implementing tool execution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Visualize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the agent graph\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph structure: START ‚Üí assistant ‚Üí [conditional] ‚Üí tools ‚Üí assistant ‚Üí END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üé® Notice the difference from Topic 1:**\n",
    "- Topic 1: Linear (START ‚Üí assistant ‚Üí END)\n",
    "- Topic 2: Has a **cycle** (tools can loop back to assistant)\n",
    "\n",
    "This is agentic behavior - the agent can use tools multiple times if needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Testing the Tool-Using Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test function ready\n"
     ]
    }
   ],
   "source": [
    "# Helper function\n",
    "def run_agent(user_input: str, thread_id: str = \"test_session\"):\n",
    "    \"\"\"\n",
    "    Run the agent and display the conversation.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üë§ User: {user_input}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    \n",
    "    for message in result[\"messages\"]:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            continue  # Already printed\n",
    "        elif isinstance(message, AIMessage):\n",
    "            if message.tool_calls:\n",
    "                print(f\"ü§ñ Agent: [Calling tool: {message.tool_calls[0]['name']}]\")\n",
    "            else:\n",
    "                print(f\"ü§ñ Agent: {message.content}\")\n",
    "        elif isinstance(message, ToolMessage):\n",
    "            print(f\"üîß Tool Result: {message.content[:100]}...\" if len(message.content) > 100 else f\"üîß Tool Result: {message.content}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\\n\")\n",
    "\n",
    "print(\"‚úÖ Test function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Calculator Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: What is 12345 * 67890?\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 838102050\n",
      "ü§ñ Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"What is 12345 * 67890?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Expected Flow:**\n",
    "1. Agent sees it needs to calculate\n",
    "2. Calls calculator tool\n",
    "3. Gets result from tool\n",
    "4. Returns formatted answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Text Analyzer Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: Analyze this text: 'RAG systems combine retrieval with generation. They are very useful!'\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 838102050\n",
      "ü§ñ Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "ü§ñ Agent: [Calling tool: text_analyzer]\n",
      "üîß Tool Result: Text Analysis:\n",
      "- Characters: 68\n",
      "- Words: 10\n",
      "- Sentences: 2\n",
      "- First 50 chars: RAG systems combine ret...\n",
      "ü§ñ Agent: Here is the analysis of the text:\n",
      "\n",
      "- **Characters**: 68\n",
      "- **Words**: 10\n",
      "- **Sentences**: 2\n",
      "- **First 50 characters**: \"RAG systems combine retrieval with generation. The...\"\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"Analyze this text: 'RAG systems combine retrieval with generation. They are very useful!'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: No Tool Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: Hello! What can you help me with?\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 838102050\n",
      "ü§ñ Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "ü§ñ Agent: [Calling tool: text_analyzer]\n",
      "üîß Tool Result: Text Analysis:\n",
      "- Characters: 68\n",
      "- Words: 10\n",
      "- Sentences: 2\n",
      "- First 50 chars: RAG systems combine ret...\n",
      "ü§ñ Agent: Here is the analysis of the text:\n",
      "\n",
      "- **Characters**: 68\n",
      "- **Words**: 10\n",
      "- **Sentences**: 2\n",
      "- **First 50 characters**: \"RAG systems combine retrieval with generation. The...\"\n",
      "ü§ñ Agent: Hello! I can assist you with a variety of tasks, including:\n",
      "\n",
      "1. **Mathematical Calculations**: I can perform calculations and solve mathematical expressions.\n",
      "2. **Text Analysis**: I can analyze text for statistics such as character count, word count, and sentence count.\n",
      "3. **General Information**: I can provide information on a wide range of topics.\n",
      "\n",
      "Feel free to ask me anything specific you'd like help with!\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"Hello! What can you help me with?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Smart Agent:** Notice it didn't use any tools - it knew a greeting doesn't need tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Wrong Tool Choice?\n",
    "\n",
    "Let's see if the agent chooses the right tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: How many words are in this sentence: 'LangGraph makes building agents easy'?\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 838102050\n",
      "ü§ñ Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "ü§ñ Agent: [Calling tool: text_analyzer]\n",
      "üîß Tool Result: Text Analysis:\n",
      "- Characters: 68\n",
      "- Words: 10\n",
      "- Sentences: 2\n",
      "- First 50 chars: RAG systems combine ret...\n",
      "ü§ñ Agent: Here is the analysis of the text:\n",
      "\n",
      "- **Characters**: 68\n",
      "- **Words**: 10\n",
      "- **Sentences**: 2\n",
      "- **First 50 characters**: \"RAG systems combine retrieval with generation. The...\"\n",
      "ü§ñ Agent: Hello! I can assist you with a variety of tasks, including:\n",
      "\n",
      "1. **Mathematical Calculations**: I can perform calculations and solve mathematical expressions.\n",
      "2. **Text Analysis**: I can analyze text for statistics such as character count, word count, and sentence count.\n",
      "3. **General Information**: I can provide information on a wide range of topics.\n",
      "\n",
      "Feel free to ask me anything specific you'd like help with!\n",
      "ü§ñ Agent: [Calling tool: text_analyzer]\n",
      "üîß Tool Result: Text Analysis:\n",
      "- Characters: 36\n",
      "- Words: 5\n",
      "- Sentences: 0\n",
      "- First 50 chars: LangGraph makes building...\n",
      "ü§ñ Agent: The sentence \"LangGraph makes building agents easy\" contains 5 words.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"How many words are in this sentence: 'LangGraph makes building agents easy'?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Expected:** Should use `text_analyzer`, not `calculator`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5: Conversational Context with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: Calculate 100 * 50\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 5000\n",
      "ü§ñ Agent: The result of \\( 100 \\times 50 \\) is 5000.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First query\n",
    "run_agent(\"Calculate 100 * 50\", thread_id=\"calc_session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: Now add 1000 to that result\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 5000\n",
      "ü§ñ Agent: The result of \\( 100 \\times 50 \\) is 5000.\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 6000\n",
      "ü§ñ Agent: Adding 1000 to the previous result gives us 6000.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Follow-up - does it remember?\n",
    "run_agent(\"Now add 1000 to that result\", thread_id=\"calc_session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéâ Amazing:** The agent remembers the previous result AND uses the calculator for the new calculation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Understanding Tool Messages\n",
    "\n",
    "Let's inspect what happens behind the scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã FULL MESSAGE HISTORY:\n",
      "\n",
      "1. HumanMessage\n",
      "   Content: What is 15 * 25?\n",
      "\n",
      "2. AIMessage\n",
      "   Tool Call: calculator({'expression': '15 * 25'})\n",
      "\n",
      "3. ToolMessage\n",
      "   Content: 375\n",
      "\n",
      "4. AIMessage\n",
      "   Content: 15 * 25 equals 375.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get full message history\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is 15 * 25?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"inspect_session\"}}\n",
    ")\n",
    "\n",
    "print(\"\\nüìã FULL MESSAGE HISTORY:\\n\")\n",
    "for i, msg in enumerate(result[\"messages\"], 1):\n",
    "    print(f\"{i}. {type(msg).__name__}\")\n",
    "    if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "        print(f\"   Tool Call: {msg.tool_calls[0]['name']}({msg.tool_calls[0]['args']})\")\n",
    "    elif isinstance(msg, ToolMessage):\n",
    "        print(f\"   Content: {msg.content}\")\n",
    "    elif hasattr(msg, 'content'):\n",
    "        print(f\"   Content: {msg.content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîç Message Flow:**\n",
    "1. `HumanMessage` - User's query\n",
    "2. `AIMessage` (with tool_calls) - Agent decides to call calculator\n",
    "3. `ToolMessage` - Result from calculator tool\n",
    "4. `AIMessage` (no tool_calls) - Agent's final answer\n",
    "\n",
    "This is the standard **ReAct** pattern: Reason ‚Üí Act ‚Üí Observe ‚Üí Respond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Adding a Third Tool (Bonus)\n",
    "\n",
    "Let's add one more tool to show how flexible this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent v2 created with 3 tools\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def coin_flip() -> str:\n",
    "    \"\"\"\n",
    "    Flip a coin and return heads or tails.\n",
    "    \n",
    "    Use this when the user wants a random choice or coin flip.\n",
    "    \n",
    "    Returns:\n",
    "        Either \"Heads\" or \"Tails\"\n",
    "    \"\"\"\n",
    "    import random\n",
    "    return random.choice([\"Heads\", \"Tails\"])\n",
    "\n",
    "# Rebuild agent with 3 tools\n",
    "tools_v2 = [calculator, text_analyzer, coin_flip]\n",
    "llm_with_tools_v2 = llm.bind_tools(tools_v2)\n",
    "\n",
    "def assistant_v2(state: MessagesState) -> dict:\n",
    "    messages = [sys_msg] + state[\"messages\"]\n",
    "    response = llm_with_tools_v2.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "builder_v2 = StateGraph(MessagesState)\n",
    "builder_v2.add_node(\"assistant\", assistant_v2)\n",
    "builder_v2.add_node(\"tools\", ToolNode(tools_v2))\n",
    "builder_v2.add_edge(START, \"assistant\")\n",
    "builder_v2.add_conditional_edges(\"assistant\", should_continue, {\"tools\": \"tools\", \"__end__\": END})\n",
    "builder_v2.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "agent_v2 = builder_v2.compile(checkpointer=MemorySaver())\n",
    "\n",
    "print(\"‚úÖ Agent v2 created with 3 tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: The coin flip result is Tails!\n"
     ]
    }
   ],
   "source": [
    "# Test coin flip\n",
    "result = agent_v2.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Flip a coin for me!\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"coin_session\"}}\n",
    ")\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    if isinstance(msg, AIMessage) and not msg.tool_calls:\n",
    "        print(f\"ü§ñ Agent: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ú® Scalability:** You can add as many tools as you need - the agent will learn to use them all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 10: Preparing for Topic 3 (Agentic RAG)\n",
    "\n",
    "In Topic 3, we'll create a **retrieval tool** that searches a vector store. It will work exactly like these tools:\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def retrieve_documents(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant documents from vector store.\"\"\"\n",
    "    docs = vectorstore.similarity_search(query)\n",
    "    return format_docs(docs)\n",
    "\n",
    "# Agent will decide: \"Do I need to retrieve documents?\"\n",
    "```\n",
    "\n",
    "This is the foundation of **Agentic RAG** - retrieval controlled by an intelligent agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11: Summary\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **Why Tools Matter**\n",
    "   - LLMs can't DO things without tools\n",
    "   - Tools extend agent capabilities\n",
    "   - Agents decide when to use tools\n",
    "\n",
    "2. **Creating Tools**\n",
    "   - Use `@tool` decorator\n",
    "   - Write clear docstrings (LLM reads them!)\n",
    "   - Include examples and error handling\n",
    "\n",
    "3. **Tool Integration**\n",
    "   - `bind_tools()` gives LLM awareness of tools\n",
    "   - OpenAI function calling enables structured tool calls\n",
    "   - ToolNode executes tools automatically\n",
    "\n",
    "4. **Conditional Routing**\n",
    "   - Check `tool_calls` to decide next step\n",
    "   - Graph can loop back to assistant after tools\n",
    "   - This enables iterative, multi-step reasoning\n",
    "\n",
    "5. **ReAct Pattern**\n",
    "   - **Reason:** Agent analyzes query\n",
    "   - **Act:** Agent calls appropriate tool\n",
    "   - **Observe:** Agent sees tool result\n",
    "   - **Respond:** Agent generates final answer\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Topic 3: Agentic RAG** ‚≠ê\n",
    "- Create a retrieval tool using Chroma vector store\n",
    "- Agent decides when to retrieve vs answer from knowledge\n",
    "- Build a complete agentic RAG system\n",
    "- The core concept of this module!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Other Practice Exercises\n",
    "\n",
    "1. **Create a new tool** that converts temperatures (Celsius ‚Üî Fahrenheit)\n",
    "2. **Test tool priority** - what happens if multiple tools could work?\n",
    "3. **Add error handling** - make a tool that sometimes fails and see how the agent handles it\n",
    "4. **Multi-tool query** - ask something that requires using TWO tools in sequence\n",
    "5. **Improve prompts** - modify the system prompt to change tool usage behavior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercises\n",
    "## Exercise 1: Build Your First Stateful Agent\n",
    "\n",
    "### Task\n",
    "Create an agent with three custom tools:\n",
    "1. **Weather tool:** Returns simulated weather for a given city\n",
    "2. **Dictionary tool:** Looks up word definitions (simulate with a small dict)\n",
    "3. **Web search tool:** Uses DuckDuckGo to search the web for information\n",
    "\n",
    "### Requirements\n",
    "1. Define tools using `@tool` decorator\n",
    "2. Bind tools to LLM\n",
    "3. Implement conditional routing (agent decides which tool to use)\n",
    "4. Handle cases where no tool is needed\n",
    "5. Install DuckDuckGo search: `pip install duckduckgo-search`\n",
    "6. Use `DDGS().text()` method for web searches\n",
    "\n",
    "### Example Queries\n",
    "- \"What's the weather in Lagos?\" ‚Üí Uses weather tool\n",
    "- \"Define the word 'ephemeral'\" ‚Üí Uses dictionary\n",
    "- \"Search for latest AI news\" ‚Üí Uses DuckDuckGo web search\n",
    "- \"What's the capital of France?\" ‚Üí No tool needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reflection Questions\n",
    "\n",
    "1. **How does the agent \"know\" which tool to use?**\n",
    "   \n",
    "2. **What role does the tool docstring play?**\n",
    "   \n",
    "3. **Why do we need conditional edges for tool-using agents?**\n",
    "   \n",
    "4. **What would happen if we didn't loop back to assistant after tools?**\n",
    "   \n",
    "5. **How is this different from just calling functions in regular Python code?**\n",
    "\n",
    "Think about these before moving to Topic 3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "**üéâ Topic 2 Complete!**\n",
    "\n",
    "You now know how to build agents that use tools! Next: **Agentic RAG** - where retrieval becomes a tool that agents control!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
